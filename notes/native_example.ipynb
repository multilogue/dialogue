{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# The OpenAI example of function use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from os.path import dirname\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "sys.path.append(dirname(find_dotenv()))\n",
    "load_dotenv()\n",
    "\"\"\"OPENAI_API_KEY or OPENAI_API_KEY_PATH,\n",
    "OPENAI_ORGANIZATION can be set... or not.\n",
    "The properly named environment variables are loaded\n",
    "into the OpenAI library by its' __init__\"\"\"\n",
    "import openai\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"69\"\n",
    "                       \"\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "}\n",
    "\n",
    "def execute_function_call(message, functions):\n",
    "    name = message[\"function_call\"][\"name\"]\n",
    "    function_to_call = functions[name]\n",
    "    arguments = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "    function_result = function_to_call(\n",
    "        location=arguments.get(\"location\"),\n",
    "        unit=arguments.get(\"unit\"),\n",
    "    )\n",
    "    return function_result\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 1: send the conversation and available functions to GPT\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Chicago, IL?\"\n",
    "    }\n",
    "]\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",  # auto is default\n",
    ")\n",
    "response_message = response[\"choices\"][0][\"message\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 2: check if GPT wanted to call a function\n",
    "if response_message.get(\"function_call\"):\n",
    "    # Step 3: call the function\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }  # only one function in this example, but you can have multiple\n",
    "    function_name = response_message[\"function_call\"][\"name\"]\n",
    "    fuction_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "    function_response = fuction_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "    # Step 4: send the info on the function call and function response to GPT\n",
    "    messages.append(response_message)  # extend conversation with assistant's reply\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )  # extend conversation with function response\n",
    "    second_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "    )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "    print(second_response)\n",
    "else:\n",
    "    print('There was no function call')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
